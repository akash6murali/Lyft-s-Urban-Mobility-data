{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary package\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extreme coordinates of San Jose\n",
    "lat_min = 37.197467\n",
    "lat_max = 37.501078\n",
    "long_min = -122.104839\n",
    "long_max = -121.702683"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.read_csv(\"data.csv\")\n",
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering out san jose records\n",
    "sanjose_df_copy = main_df[(main_df['start_station_latitude'] > lat_min) & (main_df['start_station_latitude'] < lat_max) & (main_df['start_station_longitude'] > long_min) & (main_df['end_station_longitude'] < long_max)]\n",
    "sanjose_df_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of missing values\n",
    "sanjose_df_copy.isnull().sum()/len(sanjose_df_copy)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping ride_id, start_station_id, end_station_id as they are not that important for the analysis\n",
    "sanjose_df_copy.drop(['start_station_id','end_station_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanjose_df_copy.isnull().sum()/len(sanjose_df_copy)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanjose_df_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the column start time and end time a no. of useful columns can be derrived\n",
    "# converting the start_time and end_time to datime format for further analysis\n",
    "sanjose_df_copy['start_time'] = pd.to_datetime(sanjose_df_copy['start_time'], format='%Y-%m-%d %H:%M:%S')\n",
    "sanjose_df_copy['end_time'] = pd.to_datetime(sanjose_df_copy['end_time'], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanjose_df_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ride durations\n",
    "sanjose_df_copy['ride_duration'] = sanjose_df_copy['end_time'] - sanjose_df_copy['start_time']\n",
    "\n",
    "# Convert ride durations into minutes\n",
    "sanjose_df_copy['ride_duration'] = sanjose_df_copy['ride_duration'].dt.total_seconds().div(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract day of the week for each ride from the 'started_at_datetime' value (Monday = 0, Tuesday = 1, etc.)\n",
    "sanjose_df_copy['day_of_week'] = sanjose_df_copy['start_time'].dt.dayofweek\n",
    "\n",
    "# Extract date (start) for each ride\n",
    "sanjose_df_copy['day_of_month'] = sanjose_df_copy['start_time'].dt.day\n",
    "\n",
    "# Extract hour (start) for each ride\n",
    "sanjose_df_copy['start_hour'] = sanjose_df_copy['start_time'].dt.hour\n",
    "\n",
    "sanjose_df_copy['month'] = sanjose_df_copy['start_time'].dt.month\n",
    "\n",
    "sanjose_df_copy['year'] = sanjose_df_copy['start_time'].dt.year\n",
    "\n",
    "# Map week days values\n",
    "week_days = {0:\"Monday\", 1:\"Tuesday\", 2:\"Wednesday\", 3:\"Thursday\", 4:\"Friday\", 5:\"Saturday\", 6:\"Sunday\"}\n",
    "sanjose_df_copy['day_of_week'] = sanjose_df_copy['day_of_week'].map(week_days)\n",
    "week_days_num = {\"Monday\" : 0, \"Tuesday\" : 1, \"Wednesday\" : 2, \"Thursday\" : 3, \"Friday\" : 4, \"Saturday\" : 5, \"Sunday\" : 6}\n",
    "sanjose_df_copy['day_of_week_num'] = sanjose_df_copy['day_of_week'].map(week_days_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanjose_df_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanjose_df_copy['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can drop records which has ride duration less than a minute; since these could depict accidental rides and not important to our analysis\n",
    "sanjose_df_copy = sanjose_df_copy.loc[sanjose_df_copy['ride_duration'] >= 1]\n",
    "sanjose_df_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing records which started and ended at the same station; these records are of not that use for further annalysis\n",
    "# Tolerance for considering coordinates to be the same, in degrees\n",
    "tolerance = 0.0001\n",
    "\n",
    "# Boolean mask for rows where the start and end coordinates are effectively the same\n",
    "mask = (abs(sanjose_df_copy['start_station_latitude'] - sanjose_df_copy['end_station_latitude']) < tolerance) & \\\n",
    "       (abs(sanjose_df_copy['start_station_longitude'] - sanjose_df_copy['end_station_longitude']) < tolerance)\n",
    "\n",
    "# Invert the mask to keep only the rows where the coordinates are different\n",
    "sanjose_df_copy_filtered = sanjose_df_copy[~mask]\n",
    "\n",
    "# Now sanjose_df_copy_filtered contains only the records where the start and end stations are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanjose_df_copy_filtered.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the haversine function to calculate distances\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees).\n",
    "    \"\"\"\n",
    "    # Convert decimal degrees to radians\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    r = 6371  # Radius of Earth in kilometers\n",
    "    return c * r\n",
    "\n",
    "# Assuming 'sanjose_df_copy_filtered' is your DataFrame\n",
    "# Apply the haversine function to each row to calculate the distance in km\n",
    "sanjose_df_copy_filtered['haversine_distance_km'] = sanjose_df_copy_filtered.apply(\n",
    "    lambda row: haversine(row['start_station_longitude'], row['start_station_latitude'],\n",
    "                          row['end_station_longitude'], row['end_station_latitude']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanjose_df_copy_filtered.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Speed for each ride\n",
    "sanjose_df_copy_filtered['ride_speed'] = sanjose_df_copy_filtered['haversine_distance_km'] / (sanjose_df_copy_filtered['ride_duration']) * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observing from this the max ride duration is 1499.933 mins which is more than 24 hours which is an outlier and also the max speed is 56kmph which is highly unlikely in an urban area\n",
    "# Remove 24+ hour rides and speeds over 30 KMPH\n",
    "sanjose_df_copy_filtered = sanjose_df_copy_filtered[(sanjose_df_copy_filtered['ride_duration'] <= 1440) & (sanjose_df_copy_filtered['ride_speed'] <= 30)]\n",
    "sanjose_df_copy_filtered.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rideable type distribution\n",
    "\n",
    "# Lyft-inspired color palette\n",
    "lyft_palette = [\"#FF00BF\", \"#AA00FF\", \"#FF66FF\", \"#6600FF\", \"#CC00FF\"]\n",
    "\n",
    "rideable_counts = sanjose_df_copy_filtered['rideable_type'].value_counts()\n",
    "\n",
    "# Set the aesthetic style of the plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "palette = sns.color_palette(\"bright\")\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=rideable_counts.index, y=rideable_counts.values, palette=lyft_palette)\n",
    "\n",
    "# Add the plot title and labels\n",
    "plt.title('Distribution of Rideable Types', fontsize=16)\n",
    "plt.xlabel('Rideable Type', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanjose_df_copy_filtered['rideable_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's drop docked_type since it is only a very small fraction of the whole distribution\n",
    "# Drop records where the rideable_type is 'docked_bike' directly within the original DataFrame\n",
    "sanjose_df_copy_filtered = sanjose_df_copy_filtered[sanjose_df_copy_filtered['rideable_type'] != 'docked_bike']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User type distribution\n",
    "# Count the frequency of each user type\n",
    "user_type_counts = sanjose_df_copy_filtered['member_casual'].value_counts()\n",
    "\n",
    "# Create the bar plot for user type distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=user_type_counts.index, y=user_type_counts.values, palette=lyft_palette)\n",
    "plt.title('Distribution of User Types', fontsize=16)\n",
    "plt.xlabel('User Type', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of rideable types by user type\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='rideable_type', hue='member_casual', data=sanjose_df_copy_filtered, palette=lyft_palette)\n",
    "plt.title('Distribution of Rideable Types by User Type', fontsize=16)\n",
    "plt.xlabel('Rideable Type', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.legend(title='User Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ount plot with hours and user type\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.countplot(x='start_hour', hue='member_casual', data=sanjose_df_copy_filtered, palette=lyft_palette)\n",
    "plt.title('Hourly Rides by Customer Type', fontsize=16)\n",
    "plt.xlabel('Hour of the Day', fontsize=14)\n",
    "plt.ylabel('Number of Rides', fontsize=14)\n",
    "plt.legend(title='User Type', loc='upper left')\n",
    "plt.xticks(ticks=range(0, 24), labels=[f\"{hour}:00\" for hour in range(0, 24)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we will plot the count of rides by week number, separated by rider type\n",
    "plt.figure(figsize=(15, 7))\n",
    "sns.countplot(x='day_of_week', hue='member_casual', data=sanjose_df_copy_filtered, palette=lyft_palette)\n",
    "plt.title('Weekly Rides by Rider Type', fontsize=16)\n",
    "plt.xlabel('Day', fontsize=14)\n",
    "plt.ylabel('Number of Rides', fontsize=14)\n",
    "plt.legend(title='Rider Type')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we will plot the count of rides by week number, separated by rider type\n",
    "plt.figure(figsize=(15, 7))\n",
    "sns.countplot(x='month', hue='member_casual', data=sanjose_df_copy_filtered, palette=lyft_palette)\n",
    "plt.title('monthly Rides by Rider Type', fontsize=16)\n",
    "plt.xlabel('Months', fontsize=14)\n",
    "plt.ylabel('Number of Rides', fontsize=14)\n",
    "plt.legend(title='Rider Type')\n",
    "plt.xticks(rotation=45)  # Rotate x-ticks if there are many weeks and they overlap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='day_of_month', hue='member_casual', data=sanjose_df_copy_filtered, palette=lyft_palette)\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title('Daily Rides by Rider Type', fontsize=16)\n",
    "plt.xlabel('Day of the month', fontsize=14)\n",
    "plt.ylabel('Number of Rides', fontsize=14)\n",
    "plt.legend(title='Rider Type')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='year', hue='member_casual', data=sanjose_df_copy_filtered, palette=lyft_palette)\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title('Yearly Rides by Rider Type', fontsize=16)\n",
    "plt.xlabel('Years', fontsize=14)\n",
    "plt.ylabel('Number of Rides', fontsize=14)\n",
    "plt.legend(title='Rider Type')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the list of Lat an Lng\n",
    "start_station_latitude = sanjose_df_copy_filtered.start_station_latitude.tolist()\n",
    "start_station_longitude = sanjose_df_copy_filtered.start_station_longitude.tolist()\n",
    "end_station_latitude = sanjose_df_copy_filtered.end_station_latitude.tolist()\n",
    "end_station_longitude = sanjose_df_copy_filtered.end_station_longitude.tolist()\n",
    "lat, lng = (start_station_latitude + end_station_latitude), (start_station_longitude + end_station_longitude)\n",
    "\n",
    "#Create the Map\n",
    "map = folium.Map(\n",
    "    location=[37.335480,-121.893028],\n",
    "    tiles='openstreetmap',\n",
    "    zoom_start=13\n",
    ")\n",
    "\n",
    "HeatMap(list(zip(lat, lng))).add_to(map)\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top ten popular start stations\n",
    "\n",
    "sanjose_df_copy_filtered['start_station_name'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top ten popular end stations\n",
    "\n",
    "sanjose_df_copy_filtered['end_station_name'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanjose_df_copy_filtered_no_nan = sanjose_df_copy_filtered[~sanjose_df_copy_filtered['end_station_name'].isna()]\n",
    "sanjose_df_copy_filtered_no_nan = sanjose_df_copy_filtered_no_nan[~sanjose_df_copy_filtered_no_nan['end_station_name'].isna()]\n",
    "sanjose_df_copy_filtered_no_nan = sanjose_df_copy_filtered.loc[sanjose_df_copy_filtered['start_station_name'] != sanjose_df_copy_filtered['end_station_name']]\n",
    "\n",
    "# Group rows by Start Station Name and End Station Name\n",
    "popular_stations = sanjose_df_copy_filtered_no_nan.groupby(['start_station_name','end_station_name','start_station_latitude','start_station_longitude','end_station_latitude','end_station_longitude']).size().sort_values(ascending=False)\n",
    "popular_stations = popular_stations[:10].to_frame().reset_index()    \n",
    "\n",
    "# Create a list of popular routes\n",
    "l = []\n",
    "for x in range(0, len(popular_stations)):\n",
    "    l.append([(popular_stations['start_station_latitude'][x], popular_stations['start_station_longitude'][x]), (popular_stations['end_station_latitude'][x], popular_stations['end_station_longitude'][x])])\n",
    "\n",
    "# Plot Popular Routes on a Map\n",
    "popular_map = folium.Map(location=[37.3425,-121.893028], tiles='openstreetmap', zoom_start=14)\n",
    "\n",
    "folium.PolyLine(locations = l,\n",
    "                line_opacity = 0.1).add_to(popular_map)\n",
    "\n",
    "for i in range(0,9):\n",
    "   folium.Marker(\n",
    "      location=[popular_stations['start_station_latitude'][i], popular_stations['start_station_longitude'][i]],\n",
    "      popup=popular_stations['start_station_name'][i],\n",
    "   ).add_to(popular_map)\n",
    "\n",
    "for j in range(0,9):\n",
    "   folium.Marker(\n",
    "      location=[popular_stations['end_station_latitude'][j], popular_stations['end_station_longitude'][j]],\n",
    "      popup=popular_stations['end_station_name'][j],\n",
    "   ).add_to(popular_map)\n",
    "\n",
    "popular_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanjose_df_copy_filtered['start_station_name'].nunique()\n",
    "\n",
    "sanjose_df_copy_filtered['end_station_name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanjose_df_copy_filtered.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanjose_df_copy_filtered.isnull().sum()/len(sanjose_df_copy)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanjose_df_copy_filtered.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation and Value Proposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "\n",
    "# Convert latitude and longitude to radians for use in haversine metric\n",
    "start_coords = np.radians(sanjose_df_copy_filtered[['start_station_latitude', 'start_station_longitude']].values)\n",
    "end_coords = np.radians(sanjose_df_copy_filtered[['end_station_latitude', 'end_station_longitude']].values)\n",
    "\n",
    "# Define the epsilon value in radians, assuming you want to use 1 km as the radius\n",
    "# 1 km in degrees is approximately 0.008998919 degrees. Now convert this to radians.0.0044994595(half of 1km i.e 0.5km)\n",
    "eps_rad = np.radians(0.0044994595)\n",
    "\n",
    "# Apply DBSCAN\n",
    "\n",
    "db = DBSCAN(eps=eps_rad, min_samples=500, metric='haversine')\n",
    "start_cluster_labels = db.fit_predict(start_coords)\n",
    "end_cluster_labels = db.fit_predict(end_coords)\n",
    "\n",
    "# Add the cluster labels to your dataframe\n",
    "sanjose_df_copy_filtered['start_cluster'] = start_cluster_labels\n",
    "sanjose_df_copy_filtered['end_cluster'] = end_cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unique cluster labels for start and end clusters\n",
    "unique_start_clusters = np.unique(start_cluster_labels)\n",
    "unique_end_clusters = np.unique(end_cluster_labels)\n",
    "\n",
    "# Generate custom names for each unique cluster label\n",
    "# Note: This includes handling the noise label (-1) from DBSCAN, if present\n",
    "start_cluster_names = {cluster_label: f\"Cluster_{chr(65+i)}\" for i, cluster_label in enumerate(unique_start_clusters)}\n",
    "end_cluster_names = {cluster_label: f\"Cluster_{chr(65+i)}\" for i, cluster_label in enumerate(unique_end_clusters)}\n",
    "\n",
    "# If you have noise (-1), you might want to assign it a specific name\n",
    "start_cluster_names[-1] = \"Noise\"\n",
    "end_cluster_names[-1] = \"Noise\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the custom names to the 'start_cluster' and 'end_cluster' columns\n",
    "sanjose_df_copy_filtered['start_cluster'] = sanjose_df_copy_filtered['start_cluster'].map(start_cluster_names)\n",
    "sanjose_df_copy_filtered['end_cluster'] = sanjose_df_copy_filtered['end_cluster'].map(end_cluster_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_clusters = sanjose_df_copy_filtered['start_cluster'].value_counts()\n",
    "start_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_clusters = sanjose_df_copy_filtered['end_cluster'].value_counts()\n",
    "end_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanjose_df_copy_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross-cluster analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of trips between clusters\n",
    "trip_counts_between_clusters = sanjose_df_copy_filtered.groupby(['start_cluster', 'end_cluster']).size().reset_index(name='trip_count')\n",
    "trip_counts_between_clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the trip counts to find the most frequent trips\n",
    "sorted_trip_counts = trip_counts_between_clusters.sort_values(by='trip_count', ascending=False)\n",
    "\n",
    "# Display the top 10 most frequent trips between clusters\n",
    "print(sorted_trip_counts.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the data to create a matrix suitable for a heatmap\n",
    "trip_matrix = trip_counts_between_clusters.pivot(index='start_cluster', columns='end_cluster', values='trip_count')\n",
    "\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(trip_matrix, annot=True, fmt=\".0f\", cmap=\"YlGnBu\")\n",
    "plt.title('Trips Between Clusters')\n",
    "plt.xlabel('End Cluster')\n",
    "plt.ylabel('Start Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import branca\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import to_hex\n",
    "\n",
    "map_center = [sanjose_df_copy_filtered['start_station_latitude'].mean(), sanjose_df_copy_filtered['start_station_longitude'].mean()]\n",
    "m = folium.Map(location=map_center, zoom_start=13)\n",
    "\n",
    "cmap = cm.get_cmap('Set1')\n",
    "\n",
    "# Define the color mapping function\n",
    "def color_producer(cluster):\n",
    "    if cluster == -1:\n",
    "        return '#000000' # Color for noise\n",
    "    else:\n",
    "        return to_hex(cmap(cluster))\n",
    "\n",
    "# Add markers to the map\n",
    "for idx, row in sanjose_df_copy_filtered.iterrows():\n",
    "    if row['start_cluster'] != -1:\n",
    "        folium.CircleMarker(\n",
    "            location=[row['start_station_latitude'], row['start_station_longitude']],\n",
    "            radius=5,\n",
    "            color=color_producer(row['start_cluster']),\n",
    "            fill=True\n",
    "        ).add_to(m)\n",
    "\n",
    "# Create a legend\n",
    "legend_html = '''\n",
    "<div style=\"position: fixed; \n",
    "     bottom: 50px; left: 50px; width: 150px; height: 90px; \n",
    "     border:2px solid grey; z-index:9999; font-size:14px;\n",
    "     \">&nbsp; Cluster Legend <br>\n",
    "     &nbsp; Cluster A &nbsp; <i class=\"fa fa-circle\" style=\"color:{}\"></i><br>\n",
    "     &nbsp; Cluster O &nbsp; <i class=\"fa fa-circle\" style=\"color:{}\"></i>\n",
    "</div>'''.format(color_producer(0), color_producer(1))  # Add more lines as needed\n",
    "\n",
    "# Add the legend to the map\n",
    "m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "# Show the map\n",
    "m\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "coords = sanjose_df_copy_filtered[['start_station_latitude', 'start_station_longitude']].apply(np.radians).values\n",
    "\n",
    "# Use NearestNeighbors to find the average distance to the k-th nearest neighbor\n",
    "nearest_neighbors = NearestNeighbors(n_neighbors=500, metric='haversine')\n",
    "neighbors = nearest_neighbors.fit(coords)\n",
    "distances, indices = neighbors.kneighbors(coords)\n",
    "\n",
    "# Sort distance values and plot them to find the best 'eps'\n",
    "distances = np.sort(distances, axis=0)\n",
    "distances = distances[:, 1]  # Take the distance to the 2nd nearest neighbor\n",
    "plt.plot(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from branca.element import Template, MacroElement\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import to_hex\n",
    "\n",
    "# Define the colormap\n",
    "# Get the number of unique clusters (excluding noise)\n",
    "unique_clusters = set(sanjose_df_copy_filtered[sanjose_df_copy_filtered['start_cluster'] != -1]['start_cluster'])\n",
    "cmap = cm.get_cmap('Set1', len(unique_clusters))\n",
    "\n",
    "# Define the color mapping function\n",
    "def color_producer(cluster_label):\n",
    "    if cluster_label == -1:\n",
    "        return '#000000'  # Noise\n",
    "    else:\n",
    "        # Normalize cluster label to [0, len(unique_clusters)-1] for color mapping\n",
    "        return to_hex(cmap((cluster_label - min(unique_clusters)) / (max(unique_clusters) - min(unique_clusters))))\n",
    "\n",
    "# Create a Folium map\n",
    "map_center = [sanjose_df_copy_filtered['start_station_latitude'].mean(), sanjose_df_copy_filtered['start_station_longitude'].mean()]\n",
    "m = folium.Map(location=map_center, zoom_start=13)\n",
    "\n",
    "# Add markers to the map, excluding noise\n",
    "for idx, row in sanjose_df_copy_filtered.iterrows():\n",
    "    if row['start_cluster'] != -1:  # Exclude noise\n",
    "        folium.CircleMarker(\n",
    "            location=[row['start_station_latitude'], row['start_station_longitude']],\n",
    "            radius=5,\n",
    "            color=color_producer(row['start_cluster']),\n",
    "            fill=True\n",
    "        ).add_to(m)\n",
    "\n",
    "# Start of legend HTML code\n",
    "legend_html = '''\n",
    "<div style=\"position: fixed; \n",
    "     bottom: 50px; left: 50px; width: 150px; height: {}px; \n",
    "     border:2px solid grey; z-index:9999; font-size:14px;\n",
    "     background-color: white;\">\n",
    "     &nbsp; Cluster Legend <br>\n",
    "'''.format(len(unique_clusters) * 25 + 30)  # Calculate height based on number of clusters\n",
    "\n",
    "# Dynamically add cluster colors to the legend\n",
    "for cluster_label in unique_clusters:\n",
    "    color = color_producer(cluster_label)\n",
    "    legend_html += f'&nbsp; Cluster {cluster_label} &nbsp; <i class=\"fa fa-circle fa-lg\" style=\"color:{color}\"></i><br>'\n",
    "\n",
    "# Close the legend HTML code\n",
    "legend_html += '</div>'\n",
    "\n",
    "# Add the legend to the map\n",
    "legend = MacroElement()\n",
    "legend._template = Template(legend_html)\n",
    "\n",
    "m.get_root().add_child(legend)\n",
    "\n",
    "# Show the map\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate summary statistics for ride duration within each cluster\n",
    "cluster_summary_ride_duration = sanjose_df_copy_filtered.groupby('start_cluster')['ride_duration'].describe()\n",
    "\n",
    "# Calculate summary statistics for the start hour within each cluster\n",
    "cluster_summary_start_hour = sanjose_df_copy_filtered.groupby('start_cluster')['start_hour'].describe()\n",
    "\n",
    "# Calculate the distribution of rides across days of the week for each cluster\n",
    "cluster_summary_day_of_week = sanjose_df_copy_filtered.groupby('start_cluster')['day_of_week'].value_counts().unstack(fill_value=0)\n",
    "\n",
    "# Display the calculated summaries\n",
    "print(\"Ride Duration Statistics by Cluster:\")\n",
    "print(cluster_summary_ride_duration)\n",
    "\n",
    "print(\"\\nStart Hour Statistics by Cluster:\")\n",
    "print(cluster_summary_start_hour)\n",
    "\n",
    "print(\"\\nRide Counts by Day of the Week and Cluster:\")\n",
    "print(cluster_summary_day_of_week)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ride Duration Statistics by Cluster Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=sanjose_df_copy_filtered, x='start_cluster', y='ride_duration')\n",
    "plt.title('Ride Duration Distribution by Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Ride Duration (minutes)')\n",
    "plt.show()\n",
    "\n",
    "# Start Hour Statistics by Cluster Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=cluster_summary_start_hour['count'].reset_index(), x='start_cluster', y='count')\n",
    "plt.title('Start Hour Distribution by Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Ride Counts by Day of the Week and Cluster Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(cluster_summary_day_of_week, annot=True, fmt='d', cmap='YlGnBu')\n",
    "plt.title('Ride Counts by Day of the Week and Cluster')\n",
    "plt.xlabel('Day of the Week')\n",
    "plt.ylabel('Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean ride duration for each cluster for visualization\n",
    "mean_ride_duration_per_cluster = sanjose_df_copy_filtered.groupby('start_cluster')['ride_duration'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=mean_ride_duration_per_cluster, x='start_cluster', y='ride_duration', palette=lyft_palette)\n",
    "plt.title('Average Ride Duration by Cluster')\n",
    "plt.xlabel('Clusters')\n",
    "plt.ylabel('Average Ride Duration (minutes)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_hour_distribution = sanjose_df_copy_filtered.groupby(['start_cluster', 'start_hour']).size().reset_index(name='count')\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(data=start_hour_distribution, x='start_hour', y='count', hue='start_cluster', palette='viridis')\n",
    "plt.title('Start Hour Distribution by Cluster')\n",
    "plt.xlabel('Start Hour')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Cluster', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(data=sanjose_df_copy_filtered, x='start_cluster', hue='rideable_type', palette=lyft_palette)\n",
    "plt.title('Distribution of Rideable Types by Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Rideable Type', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45)  \n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(data=sanjose_df_copy_filtered, x='start_cluster', hue='member_casual', palette=lyft_palette)\n",
    "plt.title('Distribution of User Types by Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='User Type', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45)  \n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "akos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
